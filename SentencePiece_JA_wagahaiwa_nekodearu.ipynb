{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentencePiece-JA-wagahaiwa_nekodearu",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vochicong/ai-memo/blob/master/SentencePiece_JA_wagahaiwa_nekodearu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQZWZb4Zd1dJ",
        "colab_type": "text"
      },
      "source": [
        "# 吾輩は猫である SentencePiece \n",
        "\n",
        "自然言語処理において、文章を形態素解析したり、トークン化したりする作業が欠かせない。\n",
        "ここでは夏目漱石の「吾輩は猫である」を[SentencePiece](https://github.com/google/sentencepiece/blob/6065c4a24f89401899595e14af826632d876587c/src/unigram_model_trainer_test.cc)\n",
        "でトークン化してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYks4ySfKJZ",
        "colab_type": "text"
      },
      "source": [
        "## インストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOgKysjcXIXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e1b6186-9644-42f2-81e4-c2f63eacc2d6"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.83)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBE6X05FfND8",
        "colab_type": "text"
      },
      "source": [
        "## データダウンロード\n",
        "\n",
        "「吾輩は猫である」のテキストデータをダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hgsR4nzXUGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7d7ce82f-297b-4f2e-b3b8-d451402634ec"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/google/sentencepiece/master/data/wagahaiwa_nekodearu.txt\n",
        "!wc -lm wagahaiwa_nekodearu.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-08 05:47:50--  https://raw.githubusercontent.com/google/sentencepiece/master/data/wagahaiwa_nekodearu.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1120576 (1.1M) [text/plain]\n",
            "Saving to: ‘wagahaiwa_nekodearu.txt.6’\n",
            "\n",
            "\r          wagahaiwa   0%[                    ]       0  --.-KB/s               \rwagahaiwa_nekodearu 100%[===================>]   1.07M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-11-08 05:47:50 (12.3 MB/s) - ‘wagahaiwa_nekodearu.txt.6’ saved [1120576/1120576]\n",
            "\n",
            "   2344  377212 wagahaiwa_nekodearu.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CSWUqhqgR5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a64fd944-15e2-4b33-863f-32c1cc16ee0d"
      },
      "source": [
        "!head wagahaiwa_nekodearu.txt\n",
        "!echo ......\n",
        "!tail wagahaiwa_nekodearu.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "吾輩は猫である\r\n",
            "夏目漱石\r\n",
            "-------------------------------------------------------\r\n",
            "【テキスト中に現れる記号について】\r\n",
            "《》：ルビ\r\n",
            "（例）吾輩《わがはい》は猫である\r\n",
            "｜：ルビの付く文字列の始まりを特定する記号\r\n",
            "（例）一番｜獰悪《どうあく》な種族であった\r\n",
            "［＃］：入力者注　主に外字の説明や、傍点の位置の指定\r\n",
            "　　　（数字は、JIS X 0213の面区点番号またはUnicode、底本のページと行数）\r\n",
            "......\n",
            "底本の親本：「筑摩全集類聚版夏目漱石全集」筑摩書房\n",
            "　　　1971（昭和46）年4月〜1972（昭和47）年1月\n",
            "初出：「ホトトギス」\n",
            "　　　1905（明治38）年1月〜8月\n",
            "入力：柴田卓治\n",
            "校正：渡部峰子（一）、おのしげひこ（二、五）、田尻幹二（三）、高橋真也（四、七、八、十、十一）、しず（六）、瀬戸さえ子（九）\n",
            "1999年9月17日公開\n",
            "2015年2月3日修正\n",
            "青空文庫作成ファイル：\n",
            "このファイルは、インターネットの図書館、青空文庫（http://www.aozora.gr.jp/）で作られました。入力、校正、制作にあたったのは、ボランティアの皆さんです。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnjKbuGFiNj4",
        "colab_type": "text"
      },
      "source": [
        "## SentencePiece モデルの学習\n",
        "\n",
        "トークン化のやり方を覚えさせるために、「吾輩は猫である」のテキストを与えて、\n",
        "SentencePieceに学習させます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdgHUfN6ZsIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "586ce747-30c2-4dc9-ee99-ccd7254b3d4e"
      },
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "# Train sentencepiece model. Params taken from https://github.com/google/sentencepiece/blob/d4dd947fe71c4fa4ee24ad8297beee32887d8828/src/unigram_model_trainer_test.cc\n",
        "spm.SentencePieceTrainer.train('--input=wagahaiwa_nekodearu.txt --model_prefix=wagahaiwa_nekodearu --vocab_size=8000 '\n",
        "  '--normalization_rule_name=identity --model_type=unigram  --max_sentence_length=2048')\n",
        "\n",
        "# makes segmenter instance and loads the model file\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('wagahaiwa_nekodearu.model')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQj0u5z3iibu",
        "colab_type": "text"
      },
      "source": [
        "## トークン化の実施\n",
        "\n",
        "下に定義する text をトークン化すると、 pieces に分解されることを確認しましょう。\n",
        "また、IDも取得できます。\n",
        "\n",
        "その後、piecesまたはIDから元の文章を正しく復元 (decode) できることを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH84ZOOdbgSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = (\n",
        "    \"吾輩《わがはい》は猫である。\"\n",
        "    \"名前はまだ無い。\"\n",
        "    \"どこで生れたかとんと見当《けんとう》がつかぬ。\"\n",
        "    )\n",
        "pieces = [\n",
        "          '▁', '吾輩', '《', 'わが', 'はい', '》', 'は', '猫', 'である', '。',  \n",
        "          '名前', 'はまだ', '無い', '。', \n",
        "          'どこ', 'で', '生', 'れた', 'か', 'とん', 'と', \n",
        "          '見当', '《', 'けん', 'とう', '》', 'が', 'つか', 'ぬ', '。']\n",
        "ids = [135, 449, 4, 2388, 143, 3, 16, 184, 35, 5, 679, 1950, 2578, 5, 281, 18, \n",
        "       157, 1020, 17, 424, 14, 2401, 4, 302, 236, 3, 13, 277, 152, 5]       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPf7ISTwi8tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode\n",
        "assert sp.encode_as_pieces(text) == pieces\n",
        "assert sp.encode_as_ids(text) == ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJYRIi3Bi-7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decode\n",
        "assert sp.decode_pieces(pieces) == sp.decode_ids(ids) == text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuQdZ9JejDzu",
        "colab_type": "text"
      },
      "source": [
        "## まとめ\n",
        "\n",
        "SentencePieceで簡単に「吾輩は猫である」のテキストをトークンに分解できました。\n",
        "また、バラバラに分解されたピースを使って、元の文章を再構築できました。"
      ]
    }
  ]
}