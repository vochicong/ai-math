{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # TF Agents の環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-nightly tf-agents-nightly 'gym==0.10.11'\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_agents.environments import py_environment, tf_environment, tf_py_environment, suite_gym\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Python環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name=None, minimum=0, maximum=1)\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name=None, minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n",
      "ArraySpec(shape=(), dtype=dtype('int32'), name='step_type')\n",
      "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n",
      "...............\n",
      "Total gain: 15.0\n"
     ]
    }
   ],
   "source": [
    "# Python Environment\n",
    "py_env = suite_gym.load(\"CartPole-v0\")\n",
    "act_spec, ts_spec = py_env.action_spec(), py_env.time_step_spec()\n",
    "for x in (act_spec, ts_spec.observation, ts_spec.step_type, ts_spec.discount, ts_spec.reward):\n",
    "    print(x)\n",
    "\n",
    "ts = py_env.reset()\n",
    "gain = 0\n",
    "while not ts.is_last():\n",
    "    action = np.random.randint(2)\n",
    "    ts = py_env.step(action)\n",
    "    print('.', end='')\n",
    "    gain += ts.reward\n",
    "print(\"\\nTotal gain:\", gain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Python環境をTF環境でラッピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0409 01:20:37.019726 4640912832 deprecation.py:237] From <ipython-input-3-9b8f7d23c2da>:9: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0409 01:20:37.021908 4640912832 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "W0409 01:20:37.026283 4640912832 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "W0409 01:20:37.029671 4640912832 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "W0409 01:20:37.032709 4640912832 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "W0409 01:20:37.035305 4640912832 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedTensorSpec(shape=(), dtype=tf.int64, name=None, minimum=array(0), maximum=array(1))\n",
      "BoundedTensorSpec(shape=(4,), dtype=tf.float32, name=None, minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
      "      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n",
      "      dtype=float32))\n",
      "TensorSpec(shape=(), dtype=tf.int32, name='step_type')\n",
      "BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))\n",
      "TensorSpec(shape=(), dtype=tf.float32, name='reward')\n",
      "............\n",
      " tf.Tensor([12.], shape=(1,), dtype=float32)\n",
      "\n",
      "Total gain: 12.0\n"
     ]
    }
   ],
   "source": [
    "# Wrapping a PyEnv in TF\n",
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "act_spec, ts_spec = tf_env.action_spec(), tf_env.time_step_spec()\n",
    "for x in (act_spec, ts_spec.observation, ts_spec.step_type, ts_spec.discount, ts_spec.reward):\n",
    "    print(x)\n",
    "\n",
    "ts = tf_env.reset()\n",
    "gain = 0\n",
    "while not ts.is_last():\n",
    "    action = tf.random_uniform([1], 0, 2, dtype=tf.int32)\n",
    "    ts = tf_env.step(action)\n",
    "    print('.', end='')\n",
    "    gain += ts.reward\n",
    "print(\"\\n\", gain)\n",
    "print(\"\\nTotal gain:\", gain.numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
